{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consignes pour le TP spaCY"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectifs\n",
    "\n",
    "L'objectif du TP est d'utiliser les fonctionnalités de spaCy pour extraire de l'information pertinente d'un texte en français.\n",
    "Pour ce faire, vous pouvez vous aider des notebooks utilisés lors de la séance ainsi que de la [documentation](https://spacy.io/usage/linguistic-features) en ligne."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prise en main de l'outil\n",
    "\n",
    "Commençons par importer la librairie spaCy ainsi que le module Matcher : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partons ensuite d'un texte d'exemple en français tiré de [Wikipédia](https://fr.wikipedia.org/wiki/ChatGPT) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"ChatGPT (Chat Generative Pre-trained Transformer) est un prototype d'agent conversationnel utilisant l'intelligence artificielle, développé par OpenAI et spécialisé dans le dialogue.\n",
    "L'agent conversationnel de ChatGPT repose sur le modèle de langage GPT d'OpenAI, et est affiné en continu grâce à l'utilisation de techniques d'apprentissage supervisé et d'apprentissage par renforcement.\n",
    "ChatGPT est capable de générer des réponses à des questions, de compléter des phrases, de traduire des textes, d'écrire des articles et de tenir des conversations avec des humains. Il peut également synthétiser des textes suivant un ensemble de contraintes, telles que le ton, le style et le sujet. Il a été utilisé dans diverses applications, telles que la génération de sous-titres pour des vidéos et la création de chatbots.\n",
    "En raison de ses capacités multiples, le prototype suscite également des inquiétudes. Sont craints des détournements à des fins malveillantes, des risques de plagiat dans le monde académique et de possibles suppressions d'emplois dans certains secteurs. ChatGPT soulève également des préoccupations en matière de sécurité et de confidentialité, car le modèle peut être utilisé pour générer des faux textes et des informations trompeuses.\n",
    "Lancé en novembre 2022 dans une version gratuite et non connectée à Internet, ChatGPT bénéficie d'une large exposition médiatique et reçoit un accueil globalement positif, bien que son exactitude factuelle soit critiquée.\n",
    "En janvier 2023, ChatGPT compte plus de 100 millions de comptes enregistrés.\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Téléchargeons le modèle spaCy pour le français (fr), de petite taille (sm = small) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.3/16.3 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle peut à présent être chargé en mémoire, et le texte converti en objet spaCy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "doc = nlp(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définissons un pattern qui indique que l'on recherche tous les mots dont le Part-of-Speech (POS) est de type \"nom commun\" (NOUN) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# un premier pattern très simple\n",
    "pattern1 = [[{\"POS\": \"NOUN\"}]]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons ce que spaCy trouve comme matches (noms) dans notre texte : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained\n",
      "prototype\n",
      "intelligence\n",
      "dialogue\n",
      "ChatGPT\n",
      "modèle\n",
      "langage\n",
      "continu\n",
      "grâce\n",
      "utilisation\n",
      "techniques\n",
      "apprentissage\n",
      "apprentissage\n",
      "renforcement\n",
      "réponses\n",
      "questions\n",
      "phrases\n",
      "textes\n",
      "articles\n",
      "conversations\n",
      "humains\n",
      "textes\n",
      "ensemble\n",
      "contraintes\n",
      "ton\n",
      "style\n",
      "sujet\n",
      "applications\n",
      "génération\n",
      "sous-titres\n",
      "vidéos\n",
      "création\n",
      "chatbots\n",
      "raison\n",
      "capacités\n",
      "prototype\n",
      "inquiétudes\n",
      "craints\n",
      "détournements\n",
      "fins\n",
      "malveillantes\n",
      "risques\n",
      "plagiat\n",
      "monde\n",
      "emplois\n",
      "secteurs\n",
      "préoccupations\n",
      "matière\n",
      "sécurité\n",
      "confidentialité\n",
      "modèle\n",
      "textes\n",
      "informations\n",
      "novembre\n",
      "version\n",
      "large\n",
      "exposition\n",
      "accueil\n",
      "exactitude\n",
      "janvier\n",
      "millions\n",
      "comptes\n"
     ]
    }
   ],
   "source": [
    "def match_pattern(pattern):\n",
    "    \"\"\"Take a pattern as input and return matches (with longest match)\"\"\"\n",
    "    matcher = Matcher(nlp.vocab)\n",
    "    matcher.add(\"\", pattern)\n",
    "    matches = matcher(doc)\n",
    "    spans = [doc[start:end] for _, start, end in matches]\n",
    "    for span in spacy.util.filter_spans(spans):\n",
    "      print(span)\n",
    "\n",
    "match_pattern(pattern1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy trouve une soixantaine de noms, dont quelques faux positifs.\n",
    "\n",
    "Essayons à présent un pattern légèrement plus complexe : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'intelligence artificielle\n",
      "ses capacités multiples\n",
      "le monde académique\n",
      "des informations trompeuses\n",
      "une version gratuite\n",
      "son exactitude factuelle\n"
     ]
    }
   ],
   "source": [
    "pattern2 = [[\n",
    "            {\"POS\": \"DET\"}, \n",
    "            {\"POS\": \"NOUN\"},\n",
    "            {\"POS\": \"ADJ\"}\n",
    "           ]]\n",
    "\n",
    "match_pattern(pattern2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est possible de rendre certains éléments optionnels ou de les répéter avec les opérateurs ? (0 ou 1), * (0 ou plus) et + (1 ou plus) ainsi que {1} (exactement 1) etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l'intelligence artificielle\n",
      "apprentissage supervisé\n",
      "ses capacités multiples\n",
      "le monde académique\n",
      "des informations trompeuses\n",
      "une version gratuite\n",
      "exposition médiatique\n",
      "son exactitude factuelle\n",
      "comptes enregistrés\n"
     ]
    }
   ],
   "source": [
    "pattern3 = [[\n",
    "            {\"POS\": \"DET\", \"OP\": \"?\"}, \n",
    "            {\"POS\": \"NOUN\", \"OP\": \"{1}\"},\n",
    "            {\"POS\": \"ADJ\", \"OP\": \"+\"}\n",
    "           ]]\n",
    "\n",
    "match_pattern(pattern3)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est également possible de fournir une liste de patterns : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat\n",
      "Pre\n",
      "-\n",
      "Transformer\n",
      "intelligence artificielle\n",
      "OpenAI\n",
      "GPT\n",
      "OpenAI\n",
      "apprentissage supervisé\n",
      "diverses applications\n",
      "capacités multiples\n",
      "monde académique\n",
      "faux textes\n",
      "informations trompeuses\n",
      "Lancé\n",
      "version gratuite\n",
      "Internet\n",
      "ChatGPT\n",
      "exposition médiatique\n",
      "exactitude factuelle\n",
      "comptes enregistrés\n"
     ]
    }
   ],
   "source": [
    "patterns = [\n",
    "    [{\"POS\": \"NOUN\"}, {\"POS\": \"ADJ\"}],\n",
    "    [{\"POS\": \"ADJ\"}, {\"POS\": \"NOUN\"}],\n",
    "    [{\"POS\": \"PROPN\"}]\n",
    "]\n",
    "\n",
    "match_pattern(patterns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ceci permet d'inclure les adjectifs placés avant le nom, ainsi que les noms propres.\n",
    "\n",
    "## Travail à remettre\n",
    "\n",
    "Choisissez un texte en français de longueur moyenne (entre 500 et 1000 mots) sur un sujet au choix, par exemple issu de Wikipédia, et remplacez le texte d'exemple ci-dessus. Vous pouvez travailler directement dans la copie du notebook enregistrée sur votre Google Drive, ou bien dans un fichier local. \n",
    "\n",
    "Enrichissez la liste de patterns pour couvrir un maximum de syntagmes nominaux valides, tout en excluant les autres constructions syntaxiques. Il faut donc trouver un équilibre en bruit et silence pour minimiser à la fois les faux négatifs (syntagmes valides mais non reconnus par le matcher) et les faux positifs (matches reconnus par erreur qui viennent \"polluer\" la liste des résultats).\n",
    "\n",
    "Appliquez ensuite deux des autres analyses de spaCy vues lors du TP (tokenisation, lemmatization, POS-tagging, parsing, named-entity recognition...) à votre texte et évaluez les résultats obtenus. \n",
    "\n",
    "Exécutez ces premières analyses avec le modèle `fr_core_news_sm`. Est-il à la hauteur pour les tâches choisies ? Expérimentez ensuite avec (au moins) un modèle plus conséquent : `fr_core_news_md` (medium), `fr_core_news_lg` (large) ou `fr_dep_news_trf` (transformer) pour voir si cela améliore les résultats. N'hésitez pas à vous référer à la [documentation](https://spacy.io/models/fr) pour plus de détails.\n",
    "\n",
    "Une fois que vous êtes satisfaits des résultats obtenus, rédigez un court rapport (5 pages maximum) en PDF pour expliquer le contexte du TP, le texte choisi, votre démarche ainsi que les analyses effectuées et les performances des différents modèles utilisés pour le français.\n",
    "\n",
    "Le rapport est à remettre sur l'UV pour le **lundi 26 mai 23h59** au plus tard. Il s'agit d'un travail **strictement individuel** qui ne peut donc PAS se faire en groupe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".inglin_venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
