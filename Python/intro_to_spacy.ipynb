{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction à SpaCy\n",
    "\n",
    "[Spacy](https://spacy.io/) est une librairie open source très répandue pour effectuer des tâches NLP à travers Python. Elle permet entre autres de faire de la segmentation de phrases, du POS tagging, de la lemmatisation, de l'analyse syntaxique, de l'extraction de _patterns_, mais aussi des tâches plus complexes comme de la classification de textes.\n",
    "\n",
    "Spacy est conçu pour être rapide, efficace et facile à utiliser. Il dispose de ressources pour un grand nombre de langues, dont l'anglais, le français, et le néerlandais.\n",
    "\n",
    "Dans le cadre du TP à rendre, vous serez amenés à utiliser SpaCy. Ce notebook vous donne quelques bases afin de vous familiariser avec l'outil et de vous préparer pour le TP.\n",
    "\n",
    "Dans ce notebook, nous allons installer SpaCy et importer les ressources du Français. Ensuite, nous allons explorer les outils disponibles à travers l'analyse d'un texte."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation\n",
    "\n",
    "Nous allons ici installer la librairie SpaCy et télécharger le modèle français: nous utiliserons ici le modèle \"medium\" (`md`). Pour de meilleures performances, vous pouvez utiliser le modèle \"large\" (`lg`) ou \"transformer\" (`trf`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install spacy tabulate\n",
    "!python -m spacy download fr_core_news_md"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons ensuite importer SpaCy dans le code python et instantier un \"objet\" appelé `nlp` qui contiendra le modèle qu'on vient d'installer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyse d'un texte\n",
    "\n",
    "Nous allons choisir un texte, que l'on va découper en phrases. Ensuite, on analysera plus en détails la première phrase du texte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Le traitement automatique du langage naturel (NLP) est une branche de l'intelligence artificielle qui s'intéresse à la compréhension et à l'analyse du langage humain par des machines. Le NLP permet d'extraire des informations pertinentes à partir de textes, de reconnaître les entités nommées, de comprendre les relations entre les mots et les phrases, et de générer des textes automatiquement. Les applications courantes du NLP incluent la traduction automatique, la reconnaissance de la parole, l'analyse de sentiments, la résumé automatique de textes et l'analyse de l'opinion. Les techniques de NLP peuvent être utilisées dans de nombreux domaines, tels que la finance, la santé, le commerce électronique et les médias sociaux, pour aider les entreprises à mieux comprendre les besoins et les préférences des utilisateurs.\"\"\"\n",
    "\n",
    "# Application de l'analyseur NLP sur le document\n",
    "doc = nlp(text)\n",
    "\n",
    "# Affichage de toutes les phrases\n",
    "for sentence in doc.sents:\n",
    "    print(sentence.text)\n",
    "    print(\"------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Focalisons-nous sur la première phrase du texte et commençons par la diviser en mots (tokenization). En fait, SpaCy a déjà fait le travail pour nous: la phrase est elle-même considérée comme une liste de mots. On peut donc utiliser une boucle pour itérer à travers les mots de la phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_sentence = list(doc.sents)[0]\n",
    "\n",
    "for word in first_sentence:\n",
    "    print(word.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme nous l'avons présenté plus haut, SpaCy est avant tout un module d'analyse NLP. Il applique des analyses à tous les niveaux (phrase, segments, mots). Par exemple, chacun des mots est associé à une série d'attributs. On peut alors récupérer son `pos`, son `lemme`, ses `informations mortphologiques`, et sa `fonction` dans la phrase. Ici nous utiliserons le module `tabulate` afin d'afficher les résultats dans un tableau, pour des raisons de visibilité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate\n",
    "\n",
    "headers = [\"Word\", \"POS\", \"Lemma\", \"Morphology\", \"Dependency\"]\n",
    "\n",
    "tokens = []\n",
    "for word in first_sentence:\n",
    "    tokens.append([word.text, word.pos_, word.lemma_, word.morph, word.dep_])\n",
    "    \n",
    "print(tabulate(tokens, headers=headers))\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme souligné plus haut, les analyses se font au niveau du mot, mais aussi de la phrase. Il est dès lors possible d'analyser les dépendances au sein de la phrase. SpaCy propose même de visualiser ces dépendances sous la forme d'un arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy import displacy\n",
    "\n",
    "displacy.render(first_sentence, style=\"dep\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Entités nommées\n",
    "\n",
    "SpaCy propose également un détecteur d'entités nommées. Une \"entité nommée\" désigne des mots ou expressions qui identifient spécifiquement des personnes, des lieux, des organisations, etc., dans un texte. C'est un concept clé en traitement du langage naturel pour classer ces éléments dans des catégories prédéfinies.\n",
    "\n",
    "Voici un exemple d'utilisation via l'analyse d'une nouvelle phrase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Barack Obama et Donald Trump ont visité le Musée du Louvre à Paris en septembre dernier.\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "headers = [\"Entity\", \"Label\"]\n",
    "entities = []\n",
    "for entity in doc.ents:\n",
    "    entities.append([entity.text, entity.label_])\n",
    "\n",
    "print(tabulate(entities, headers=headers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Vectorisation et similarité sémantique\n",
    "\n",
    "SpaCy propose également la possibilité de calculer les `embeddings` (vecteurs) de mots et de documents. Cela permet de calculer la proximité sémantique entre des documents par exemple. Vous souvenez-vous du score BERT que nous avons vu dans la partie traduction automatique du cours ? Elle se basait sur ces embeddings !\n",
    "\n",
    "Faisons quelques tests:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_1 = \"Je bois un capuccino et mange un croissant.\"\n",
    "sentence_2 = \"Je bois un verre de vin et mange une pizza\"\n",
    "sentence_3 = \"Le chien est dans le jardin.\"\n",
    "sentence_4 = \"Le chat est dans la prairie\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = nlp(sentence_1)\n",
    "doc2 = nlp(sentence_3)\n",
    "\n",
    "print(doc1.similarity(doc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'évaluer les similarités au sein d'un corpus de phrases, il est également possible de créer une matrice de similarités et de la représenter sous forme d'une `heatmap` (représentation graphique des données où les valeurs sont exprimées par des couleurs)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns  \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sentences = [sentence_1, sentence_2, sentence_3, sentence_4]\n",
    "\n",
    "similarity = []\n",
    "for sentence in sentences:\n",
    "    doc = nlp(sentence)\n",
    "    sim = []\n",
    "    for sentence in sentences:\n",
    "        doc1 = nlp(sentence)\n",
    "        sim.append(doc.similarity(doc1))\n",
    "    similarity.append(sim)\n",
    "\n",
    "sns.heatmap(similarity, annot=True, xticklabels=sentences, yticklabels=sentences)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "Nous avons vu ici les bases de l'analyse NLP à travers SpaCy. Mais l'outil offre des possibilités beaucoup plus larges. Si cela vous intéresse, n'hésitez pas à parcourir la [documentation en ligne](https://spacy.io/) de l'outil qui est exhaustive et très bien rédigée.\n",
    "\n",
    "Dans le cadre du TP, vous aurez l'occasion de vous familiariser avec le [Matcher](https://spacy.io/api/matcher), qui permet d'extraire des segments de texte sur la base de _patterns_ linguistiques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
